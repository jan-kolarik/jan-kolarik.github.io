[{"content":"Intro A common use case for DNF5 API is installing packages, which is quite straightfoward.\nFirst, we need to create a Base, the core object that holds a runtime environment. We load its configuration from the system and run the setup method to prepare the environment.\nNext, we can prepare a repository sack, which holds information about configured repositories and the state of local and remote packages, while potentially refreshing metadata from remote servers if needed.\nWith the setup complete, we can tell DNF5 what we want to do, in this case, install our package. This is done by configuring the Goal object.\nAfter defining our intention, we can proceed to calculate the transaction, determining the necessary actions to achieve our goal. Finally, we can perform the resulting action, which is downloading and installing the packages.\nAn example Python script that accomplishes this might look like this:\nimport libdnf5 base = libdnf5.base.Base() base.load_config_from_file() base.setup() sack = base.get_repo_sack() sack.create_repos_from_system_configuration() sack.update_and_load_enabled_repos(True) goal = libdnf5.base.Goal(base) goal.add_install(\u0026#39;my-awesome-package\u0026#39;) transaction = goal.resolve() transaction.download() transaction.run() After this point, if everything went well, the package should be successfully installed on the system.\nWhat could be tricky is when trying to use the API after the transaction. The problem is that the existing repository sack does not reflect the updated state after the transaction was executed. This is because managing that state with connected third-party libraries would be very difficult.\nUse information from the Transaction object If you only need to query information about the post-transaction state, you can use the data provided by the Transaction object.\nThe get_transaction_packages() method can be particularly useful for this purpose. It allows us to query which packages were involved in the transaction, the specific actions taken with these packages, and any packages they may have been replaced with.\nFor example, let\u0026rsquo;s say we want to retrieve a list of new files that were installed during the transaction. In this case, we\u0026rsquo;ll need to pre-load the filelists metadata in DNF5 before loading the repository sack. We can do this by adding the following code:\nbase.get_config().get_optional_metadata_types_option().add_item(\u0026#39;filelists\u0026#39;) Then, you can use the helper function transaction_item_action_is_inbound to filter only inbound packages from the transaction. Finally, you can query the package files contained in the transaction:\nnewly_installed_files = set() for transaction_package in transaction.get_transaction_packages(): action = transaction_package.get_action() if libdnf5.base.transaction.transaction_item_action_is_inbound(action): package_files = transaction_package.get_package().get_files() newly_installed_files |= set(package_files) Use the RPM API Another alternative is to use the underlying RPM API. This should be the most effective way for querying information about installed packages, as we are directly reading the data from the SQLite database:\nimport rpm # Prepare the transaction set while ignoring package signatures verification transaction_set = rpm.TransactionSet() transaction_set.setVSFlags(rpm._RPMVSF_NOSIGNATURES) # Find the newest package in the database last_package = max(transaction_set.dbMatch(), key=lambda package: package[rpm.RPMTAG_INSTALLTIME]) # Get packages only related to the latest transaction last_packages = transaction_set.dbMatch(rpm.RPMTAG_INSTALLTID, last_package[rpm.RPMTAG_INSTALLTID]) # Aggregate all related files files = set() for package in last_packages: files |= set(package[rpm.RPMTAG_FILENAMES]) Start with the new Base When we want to perform multiple transactions in a row, the easiest way is probably to create a fresh new Base each time. If we would continue with the use case of installing packages, we can prepare a helper method in our script for this purpose:\nimport libdnf5 def install_package(spec): base = libdnf5.base.Base() base.load_config_from_file() base.setup() sack = base.get_repo_sack() sack.create_repos_from_system_configuration() sack.update_and_load_enabled_repos(True) goal = libdnf5.base.Goal(base) goal.add_install(spec) transaction = goal.resolve() transaction.download() transaction.run() for package in [\u0026#39;my-awesome-package\u0026#39;, \u0026#39;another-great-package\u0026#39;]: install_package(package) References DNF5 upstream RPM upstream ","permalink":"https://jan-kolarik.github.io/posts/dnf5-api-after-transaction/","summary":"What happens to the existing sack and how to deal with that","title":"Using DNF5 API after running the transaction"},{"content":" Intro On a bit different note, recently I was trying to help my father with adding debugging support for Arduino Mega 2560 microcontroller board without need to use any additional hardware kit.\nFor Windows, there is a great tutorial for that, but we need to setup several things differently in the Linux environment and I didn\u0026rsquo;t find any easy-to-use guide for that.\nSo I want to share my approach with you, definitely nothing world-shattering, but could be useful for anyone with similar intention or might save you some time from being stuck in one place for too long.\nEnvironment Fedora Linux (but should be applicable to any other distro) Visual Studio Code + Arduino extension Arduino CLI avr_debug Building and uploading First we need to setup the building of our project and make it possible to upload the binary into the board.\nPrepare VS Code Install the Arduino CLI tool to provide an all-in-one solution for Arduino boards.\nThen we need to install \u0026amp; enable the Arduino extension in the VS Code. In the extension\u0026rsquo;s configuration we need to modify some fields:\nArduino: Command Path (arduino.commandPath) \u0026ndash; set arduino-cli Arduino: Path (arduino.path) \u0026ndash; set /path/to/your/arduino-cli/binary Arduino: Use Arduino Cli (arduino.useArduinoCli) \u0026ndash; set true Initialize the Arduino project with the Arduino: Initialize command, f.e. by selecting it from the command palette using the F1 key in VS Code. This will generate the empty .ino source file and the default arduino.json extension config for our project in the .vscode folder. You will also need to rename this existing .ino file to match the name of the project.\nOpen the Arduino: Board Manager command and install the Arduino AVR Boards package to add support for our microcontroller board.\nUsing the bottom status bar in VS Code, select the Arduino Mega board type.\nNow you can try to compile the empty project using the Arduino: Verify command which is also available under the icon in the editor\u0026rsquo;s top bar.\nDeploy a simple program To be able to upload our program to the actual board, it might be needed to add appropriate user rights by adding the current user to the dialout or tty group:\nsudo usermod -a -G dialout $USER It will need a logout or restart.\nConnect the board to the USB and select the /dev/ttyUSB0 port from the bottom status bar.\nWe should be able now to upload the program to the board with the Arduino: Upload command.\nTo see if it is really working you can add some simple blinking to the .ino source:\nvoid setup() { pinMode(LED_BUILTIN, OUTPUT); } void loop() { digitalWrite(LED_BUILTIN, HIGH); delay(1000); digitalWrite(LED_BUILTIN, LOW); delay(1000); } Debugging Here we\u0026rsquo;ll add support for debugging our board from the VS Code using just the connected USB cable.\nSetup the debugger We will prepare the GDB debugger that will be running on our local computer and the avr_debug, remote stub which will be deployed to the ATMega and communicating with the GDB to allow debugging from VS Code.\nUnfortunately, for Fedora Linux, there is no maintained package with GDB for AVR architectures anymore, therefore we need to build it by ourselves. Luckily it\u0026rsquo;s very simple.\nDownload the latest GDB sources, compile it for target AVR architecture and install it in the defined directory like this:\n./configure --target=avr --prefix=${HOME}/Programs/avr-gdb make make install Then unpack the avr_debug library into the Arduino user libraries directory at ${HOME}/Arduino/libraries/avr-debugger. Put there just the library sub-directory from the default branch.\nConfigure the project Include the debugging library into our project by going to the Arduino: Library Manager, filtering the avr-debugger and clicking the Include Library button.\nNow we have the sources prepared for adding the debugging support which is as simple as adding the debug_init() function at the beginning of the setup():\n#include \u0026lt;app_api.h\u0026gt; #include \u0026lt;avr_debugger.h\u0026gt; #include \u0026lt;avr8-stub.h\u0026gt; void setup() { debug_init(); pinMode(LED_BUILTIN, OUTPUT); } void loop() { digitalWrite(LED_BUILTIN, HIGH); delay(1000); digitalWrite(LED_BUILTIN, LOW); delay(1000); } Last thing we need to do is to create a debugging configuration for VS Code, so it knows what we want to debug and how.\nI am sharing my launch.json example below. The key parts there:\nprogram points to our built program which is the .elf binary in the build folder miDebuggerPath addresses the AVR GDB binary we have built setupCommands section tells GDB what port and baud rate to use { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Debugger launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/build/example.ino.elf\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;externalConsole\u0026#34;: true, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;miDebuggerPath\u0026#34;: \u0026#34;${userHome}/Programs/avr-gdb/bin/avr-gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Set remote serial baud\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;set serial baud 115200\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: false }, { \u0026#34;description\u0026#34;: \u0026#34;Attach to serial port\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;target remote /dev/ttyUSB0\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: false } ] } ] } You can put it in the .vscode subfolder and modify it according to your environment.\nLet\u0026rsquo;s add some breakpoints! And so now we can verify and upload our program and then debug the running program in VS Code as with any other project. Just setup the breakpoints and then attach to the board using the Run and Debug from the Activity Bar.\nNote: there is one important downside of this approach and it\u0026rsquo;s that no Serial functions could be used when the debugging stub is attached. You could use the conditional compilation to enable them when not debugging. For more info, refer to the upstream project of the avr_debug author.\n","permalink":"https://jan-kolarik.github.io/posts/atmega-debug-linux/","summary":"Using Visual Studio Code to debug programs for Arduino Mega 2560","title":"Debugging Arduino without additional hardware"},{"content":"Intro If you are planning to make a presentation including some live command-line examples, the following article could be useful for you.\nI\u0026rsquo;d like to share with you my setup which results in HTML presentation containing embedded console windows which can run isolated from your host system.\nPrerequisites Following technologies are used to create the resulting presentation:\nreveal.js - framework for creating HTML presentations ttyd - tool to access Linux shell over HTTP podman - tool for managing containers Show the code first Prepare the example Let\u0026rsquo;s say we want to present and describe an example of our source code and then show the audience how it is being run on the target system using the CLI.\nHere we\u0026rsquo;ll use this simple Python snippet:\nimport random # Generate the number number = random.randint(1, 100) # Print the number print(f\u0026#39;Your lucky number is {number}.\u0026#39;) Insert it inside the presentation Suppose we have already configured and running some instance of the reveal.js presentation, we can insert a section with our code example there:\n\u0026lt;section\u0026gt; \u0026lt;h4\u0026gt;Python demo\u0026lt;/h4\u0026gt; \u0026lt;pre\u0026gt; \u0026lt;code\u0026gt; import random # Generate the number number = random.randint(1, 100) # Print the number print(f\u0026#39;Your lucky number is {number}.\u0026#39;) \u0026lt;/code\u0026gt; \u0026lt;/pre\u0026gt; \u0026lt;/section\u0026gt; Stylize the snippet Now we can play a bit more with the layout. We could change the default font-size and the width of the code block, so our snippet doesn\u0026rsquo;t contain any scrollbars and it is better centered within the presentation screen.\nBy default the reveal.js presentation has configured the highlight.js plugin for syntax highlighting, so we can define the language of our snippet and apply the colors by adding the class=\u0026quot;hljs language-python\u0026quot;.\nTo emphasize only part of the code step by step, we can use the data-line-numbers attribute where the vertical bar character denotes the transitions, f.e. \u0026quot;|1|3-4|6-7\u0026quot; means starting with the whole code highlighted, followed by just line number 1, then lines 3-4 and ending with lines 6-7.\nThe result could look like this:\n\u0026lt;section\u0026gt; \u0026lt;h4\u0026gt;Python demo\u0026lt;/h4\u0026gt; \u0026lt;pre style=\u0026#34;font-size: 18px; width: 60%;\u0026#34;\u0026gt; \u0026lt;code class=\u0026#34;hljs language-python\u0026#34; data-line-numbers=\u0026#34;|1|3-4|6-7\u0026#34;\u0026gt; import random # Generate the number number = random.randint(1, 100) # Print the number print(f\u0026#39;Your lucky number is {number}.\u0026#39;) \u0026lt;/code\u0026gt; \u0026lt;/pre\u0026gt; \u0026lt;/section\u0026gt; Add an interactive console Setup the web terminal Deploying the shell web server is very simple. When we have downloaded the ttyd binary, we just provide the port number where the daemon will be listening and providing the HTTP layer above the console.\nFollowing example will deploy ttyd web server on the port 1234 and for every connected client it will create a new process with bash:\nttyd -p 1234 bash Integrate the console Putting the console into the presentation is as simple as adding new iframe pointing to our ttyd service at http://localhost:1234/:\n\u0026lt;iframe src=\u0026#34;http://localhost:1234/\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; Tuning the visual Now to create a seamless transition between the code snippet and the console window we need to add a bit more configuration.\nWe can setup a custom font size and also change the colors for ttyd console like this:\nttyd -p 1234 -t fontSize=12 -t \u0026#39;theme={\u0026#34;background\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;foreground\u0026#34;: \u0026#34;black\u0026#34;}\u0026#39; bash In reveal.js we will stack the console frame window on the top of the code snippet while keeping it invisible until the snippet code slides are fully traversed. This could be done by including the both frames inside the parent div having the r-stack class and showing the console at the right moment by adding the fragment class to the console iframe.\nIn the end we can change the console frame size to match the code snippet.\nOne hack that could be handy when we don\u0026rsquo;t want to show the vertical scrollbar inside the console frame, but still keeping the scrolling functionality. In this case we can wrap the console in the div which will match the size of the code example frame, but we stretch the width of the actual iframe a bit, so the scrollbar is hidden. This also needs to setup overflow: hidden; in the wrapping div.\nSo the result could look like this:\n\u0026lt;section\u0026gt; \u0026lt;h4\u0026gt;Python demo\u0026lt;/h4\u0026gt; \u0026lt;div class=\u0026#34;r-stack\u0026#34;\u0026gt; \u0026lt;pre id=\u0026#34;code\u0026#34;\u0026gt; \u0026lt;code class=\u0026#34;hljs language-python\u0026#34; data-trim data-line-numbers=\u0026#34;|1|3-4|6-7\u0026#34;\u0026gt; import random # Generate the number number = random.randint(1, 100) # Print the number print(f\u0026#39;Your lucky number is {number}.\u0026#39;) \u0026lt;/code\u0026gt; \u0026lt;/pre\u0026gt; \u0026lt;div id=\u0026#34;cli-wrapper\u0026#34;\u0026gt; \u0026lt;iframe id=\u0026#34;cli\u0026#34; class=\u0026#34;fragment fade-up\u0026#34; src=\u0026#34;http://localhost:1234/\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; And the CSS now moved into it\u0026rsquo;s own stylesheet:\n#code { font-size: 18px; width: 60%; } #cli-wrapper { max-width: 60%; width: 60%; max-height: 100%; height: 100%; overflow: hidden; } #cli { max-width: 103%; width: 103%; max-height: 100%; height: 100%; } Note: I am definitely not a CSS guy, so please don\u0026rsquo;t blame me if you find anything ridiculous about the mentioned code. But, it should work 😇\nThis is the final output when running the presentation in the web browser:\nThere should have been a video here but your browser does not seem to support it. Using containers When doing more examples in the presentation it might be useful to always have an isolated environment for each demo.\nThis can be done easily by using the podman containers. We can deploy a container from the public image, do some customizations, prepare our demo environment and then serialize the state of the container. Then we can setup ttyd to run a clean container from this image every time client requests new console.\nSo if we use the Fedora Linux as an example, we can download the latest Fedora container image and get inside that:\npodman pull fedora podman run -it fedora It will redirect us inside the container terminal:\n[root@fdee00b17d43 /]# Now prepare the environment needed for the demo, like installing dependencies, copying the example scripts into the container etc.\nWhen everything is ready, we can export the container from another shell:\npodman container export fdee00b17d43 \u0026gt; container.tar Then we can import it in the image registry on local or any other computer and tagging it with example-container name by doing:\npodman image import container.tar example-container Finally we will prepare the ttyd daemon to spawn a new container for us on each attach:\nttyd -p 1234 podman run -it example-container /bin/bash We can also change the container\u0026rsquo;s hostname with -h my-hostname, so the shell on the live demo will not show the ugly auto-generated id.\nAnd of course we can prepare many containers running on different ports with various font sizes, configuration, etc.\nNote: each time client connects to the ttyd, new container is created. This also means when the page having the embedded terminal is refreshed. Therefore it may be desirable to cleanup all the related containers after the presentation is done:\npodman container rm --filter ancestor=localhost/example-container References Here are links to show you an example of such a presentation. It is from our DNF5 talk we had at FOSDEM last week:\nSources Slides Recording ","permalink":"https://jan-kolarik.github.io/posts/terminal-presentation/","summary":"How to setup a seamless interactive console within your presentation","title":"Creating slides with integrated shell"},{"content":"My name is Jan Kolárik and I\u0026rsquo;m a software engineer currently working in Red Hat.\nI first discovered Linux when I was 14 years old and a few years later I started using it as my main operating system.\nRecently, I\u0026rsquo;ve entered the world of open source as a developer, which has been my dream for a long time.\nI have experience mainly with C++, C# and Python languages and I love applying test-driven development principles in my projects wherever it\u0026rsquo;s possible. Currently I am also discovering the beauties of Rust.\n","permalink":"https://jan-kolarik.github.io/about/","summary":"About me","title":"About"},{"content":" Last weekend I\u0026rsquo;ve attended FOSDEM 2023 conference with my colleagues from the Red Hat RPM software management team. We gave a talk about the DNF5 package manager which will be the new default in Fedora Linux soon.\nIt was the first time for me speaking in public at such a huge event and it was really exciting. This whole meetup was very energizing. Lot of different positive vibes from various tracks. I hope I\u0026rsquo;ll make it there again next year.\nIf you are more interested, you can visit this link and see a recording of our presentation or any other talk from the conference.\n","permalink":"https://jan-kolarik.github.io/posts/dnf5-fosdem2023/","summary":"Presenting the upcoming Fedora Linux package manager in Brussels","title":"DNF5 at FOSDEM"}]